{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Photo OCR - Rede Neural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TyLsFF6PjTVD5n0ckP0Ug5dUR7RlZf3S",
      "authorship_tag": "ABX9TyNxA+mlN0gya7hY2SR8nHpM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "Dqi0M2CRMazO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import zipfile\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "import os\n",
        "\n",
        "from keras.models import Sequential,Input  #Keras traz uma abstração das redes neurais\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funções para tratamento e obtenção da base de dados para treino e teste da Rede neural"
      ],
      "metadata": {
        "id": "Jodib3K-b592"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_zip(path_zip,path_dest):\n",
        "  arq = zipfile.ZipFile(path_zip)\n",
        "  arq.extractall(path_dest)\n",
        "  arq.close()"
      ],
      "metadata": {
        "id": "7sTBt7gjGTCf"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matrix(path_img,like_array):\n",
        "  try:\n",
        "    img = io.imread(path_img)\n",
        "    img_gray = color.rgb2gray(img)\n",
        "    if like_array:\n",
        "      img_gray = img_gray.reshape(1,img_gray.shape[0]*img_gray.shape[1])[0]\n",
        "    return img_gray\n",
        "  except FileNotFoundError:\n",
        "    return -1 #sim, ocorreu um erro"
      ],
      "metadata": {
        "id": "nY1ydwB3Yjnf"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def built_targets_matrix(label_counts):\n",
        "\n",
        "  m = sum(label_counts[:,1])\n",
        "  n = len(label_counts)\n",
        "\n",
        "  y = np.zeros((m,n))\n",
        "\n",
        "  ini = 0\n",
        "  for i in label_counts:\n",
        "    y[ini:ini+i[1],i[0]] = 1\n",
        "    ini += i[1]\n",
        "    \n",
        "  return y"
      ],
      "metadata": {
        "id": "UDSujk8hDwNh"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def built_grand_matrix_and_targets(path,type_arq,as_array=True): #path da pasta geral\n",
        "  X = []\n",
        "  labels = []\n",
        "  for p in os.listdir(path):\n",
        "    complete_path = os.path.join(path, p)\n",
        "    \n",
        "    count_for_label = get_data_from_direct(complete_path,type_arq,as_array,X)\n",
        "\n",
        "    labels.append([int(p),count_for_label])\n",
        "  \n",
        "  y = built_targets_matrix(np.array(labels))\n",
        "\n",
        "  return np.array(X),y"
      ],
      "metadata": {
        "id": "NE31Qd-z7_mb"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_direct(path,type_arq,as_array,X):\n",
        "\n",
        "  for image_name in os.listdir(path):\n",
        "      \n",
        "      if not type_arq in image_name: continue \n",
        "      input_path = os.path.join(path, image_name)\n",
        "      data = get_matrix(input_path,as_array)\n",
        "      if type(data) != np.ndarray:continue\n",
        "\n",
        "      X.append(data)\n",
        "  \n",
        "  return len(os.listdir(path))"
      ],
      "metadata": {
        "id": "o2hk8uc6su0m"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sliding windows"
      ],
      "metadata": {
        "id": "u1vgNU1qcBcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_windows(m_img,m_pixels,n_pixels,steps): #mxn matrix\n",
        "\n",
        "  ini_i = 0\n",
        "  for i in range(m_pixels-1,m_img.shape[0],steps):\n",
        "    ini_j = 0\n",
        "    for j in range(n_pixels-1,m_img.shape[1],steps):\n",
        "      print(m_img[ini_i:i+1,ini_j:j+1].shape)\n",
        "      # Código para decidir oq fazer com o slice pego da matriz\n",
        "      ini_j += steps\n",
        "\n",
        "    ini_i += steps"
      ],
      "metadata": {
        "id": "vRLBl_BdcBCU"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rede Neural"
      ],
      "metadata": {
        "id": "9Xi939X9t33l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import argmax\n",
        "class neural_network:\n",
        "  def __init__(self,input_layer_dim,X,y):\n",
        "    self.model = Sequential()\n",
        "    self.have_input = False\n",
        "    self.input_layer_dim = input_layer_dim\n",
        "    self.X_train,self.X_test,self.y_train,self.y_test = train_test_split(X,y,test_size = 0.3)\n",
        "  \n",
        "  def summary(self):\n",
        "    return self.model.summary()\n",
        "\n",
        "  def add_layer(self,units_dim,activation_f):\n",
        "    if not self.have_input:\n",
        "      self.model.add(Input(shape=(self.input_layer_dim)))\n",
        "      #self.model.add(Dense(units=units_dim,input_dim = self.input_layer_dim, activation = activation_f))\n",
        "      self.have_input = True\n",
        "    #else:\n",
        "    self.model.add(Dense(units=units_dim,activation = activation_f))\n",
        "  \n",
        "  def train_network(self,epochs):\n",
        "    self.model.compile(optimizer='sgd',loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "    self.model.fit(self.X_train,self.y_train,epochs=epochs,\n",
        "                   validation_data=(self.X_test,self.y_test))\n",
        "  \n",
        "  def predict_class(self,example):\n",
        "    return argmax(self.model.predict(example)).numpy()[0]\n"
      ],
      "metadata": {
        "id": "5kcDkOHh1DW_"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Construindo a rede e executando testes"
      ],
      "metadata": {
        "id": "ewBf5GiCt_3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_from_zip('/content/drive/MyDrive/training_set.zip','/content/set')"
      ],
      "metadata": {
        "id": "MYpRUC0F-Uvy"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = built_grand_matrix_and_targets('/content/set','.jpg')\n",
        "print(f'{X.shape};{y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn1F9amBNNMs",
        "outputId": "ade179f8-40fb-4289-ff0e-4df4c725b299"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 784);(42000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rn = neural_network(28*28,X,y)\n",
        "\n",
        "rn.add_layer(400,'sigmoid')\n",
        "rn.add_layer(80,'sigmoid')\n",
        "rn.add_layer(10,'sigmoid')\n",
        "\n",
        "rn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osJXYGEnNNEh",
        "outputId": "93e178b5-f889-45d7-b239-b7bc3efd6934"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 400)               314000    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 80)                32080     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 346,890\n",
            "Trainable params: 346,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rn.train_network(epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmmX2Cv3NsWf",
        "outputId": "e0288146-56ad-4ff9-9b6d-044beb133e33"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "919/919 [==============================] - 5s 6ms/step - loss: 1.3641 - accuracy: 0.7221 - val_loss: 0.8219 - val_accuracy: 0.8435\n",
            "Epoch 2/10\n",
            "919/919 [==============================] - 5s 5ms/step - loss: 0.6353 - accuracy: 0.8716 - val_loss: 0.5239 - val_accuracy: 0.8834\n",
            "Epoch 3/10\n",
            "919/919 [==============================] - 5s 5ms/step - loss: 0.4469 - accuracy: 0.8958 - val_loss: 0.4160 - val_accuracy: 0.8963\n",
            "Epoch 4/10\n",
            "919/919 [==============================] - 5s 5ms/step - loss: 0.3657 - accuracy: 0.9100 - val_loss: 0.3603 - val_accuracy: 0.9068\n",
            "Epoch 5/10\n",
            "919/919 [==============================] - 4s 5ms/step - loss: 0.3182 - accuracy: 0.9182 - val_loss: 0.3281 - val_accuracy: 0.9142\n",
            "Epoch 6/10\n",
            "919/919 [==============================] - 4s 5ms/step - loss: 0.2864 - accuracy: 0.9248 - val_loss: 0.3079 - val_accuracy: 0.9172\n",
            "Epoch 7/10\n",
            "919/919 [==============================] - 5s 5ms/step - loss: 0.2617 - accuracy: 0.9312 - val_loss: 0.2839 - val_accuracy: 0.9225\n",
            "Epoch 8/10\n",
            "919/919 [==============================] - 5s 5ms/step - loss: 0.2433 - accuracy: 0.9360 - val_loss: 0.2712 - val_accuracy: 0.9248\n",
            "Epoch 9/10\n",
            "919/919 [==============================] - 5s 5ms/step - loss: 0.2285 - accuracy: 0.9393 - val_loss: 0.2636 - val_accuracy: 0.9275\n",
            "Epoch 10/10\n",
            "919/919 [==============================] - 5s 5ms/step - loss: 0.2154 - accuracy: 0.9426 - val_loss: 0.2473 - val_accuracy: 0.9329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im = get_matrix('/content/img_3.jpg',False)\n",
        "plt.gray()\n",
        "plt.imshow(im)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "nmzd5O9THrG-",
        "outputId": "ae9cce82-73de-424c-de11-b7b6acc73c80"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac0dbefc50>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rn.predict_class(im.reshape(1,28*28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqp5HeJwO5rN",
        "outputId": "f888636c-3c38-47cb-c0c3-ea1fc914001a"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    }
  ]
}